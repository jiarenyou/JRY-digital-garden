# 📜 大语言模型（LLM）论文导航

一份精心整理的大语言模型（LLM）相关论文列表，帮助研究人员和开发者快速找到重要文献。

## 📚 目录

- [📜 大语言模型（LLM）论文导航](#-大语言模型llm论文导航)
  - [📚 目录](#-目录)
  - [🤖 LLM 原理](#-llm-原理)
  - [🛠️ 微调](#️-微调)
  - [🔍 RAG](#-rag)
  - [🧠 Agent](#-agent)
  - [💡 应用](#-应用)
  - [📊 评估](#-评估)

---

## 🤖 LLM 原理

| 论文标题 | 作者 | 发表年份 | 链接 | 简介 |
| :--- | :--- | :--- | :--- | :--- |
| Attention Is All You Need | Ashish Vaswani, et al. | 2017 | [Link](https://arxiv.org/abs/1706.03762) | 提出了 Transformer 模型，彻底改变了 NLP 领域。 |
| BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | Jacob Devlin, et al. | 2018 | [Link](https://arxiv.org/abs/1810.04805) | 提出了 BERT 模型，通过双向 Transformer 预训练实现 SOTA。 |
| Language Models are Few-Shot Learners | Tom B. Brown, et al. | 2020 | [Link](https://arxiv.org/abs/2005.14165) | 介绍了 GPT-3，展示了其强大的少样本学习能力。 |

---

## 🛠️ 微调

| 论文标题 | 作者 | 发表年份 | 链接 | 简介 |
| :--- | :--- | :--- | :--- | :--- |
| Parameter-Efficient Transfer Learning for NLP | Neil Houlsby, et al. | 2019 | [Link](https://arxiv.org/abs/1902.00751) | 提出了 Adapter-tuning，一种参数高效的微调方法。 |
| LoRA: Low-Rank Adaptation of Large Language Models | Edward J. Hu, et al. | 2021 | [Link](https://arxiv.org/abs/2106.09685) | 提出了 LoRA，通过低秩分解来高效微调大模型。 |
| QLoRA: Efficient Finetuning of Quantized LLMs | Tim Dettmers, et al. | 2023 | [Link](https://arxiv.org/abs/2305.14314) | 结合量化和 LoRA，实现了在消费级硬件上微调大模型。 |

---

## 🔍 RAG

| 论文标题 | 作者 | 发表年份 | 链接 | 简介 |
| :--- | :--- | :--- | :--- | :--- |
| Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks | Patrick Lewis, et al. | 2020 | [Link](https://arxiv.org/abs/2005.11401) | 首次提出 RAG 框架，结合了预训练模型和非参数记忆。 |
| Self-Correction for Long-Term Factuality in Large Language Models | Howard Chen, et al. | 2023 | [Link](https://arxiv.org/abs/2305.14962) | 探索了如何通过自我修正来提升 RAG 系统的长期事实准确性。 |
| Corrective Retrieval Augmented Generation | Zichao Li, et al. | 2024 | [Link](https://arxiv.org/abs/2401.15884) | 提出了一种纠正性检索增强生成方法，以提高生成质量。 |

---

## 🧠 Agent

| 论文标题 | 作者 | 发表年份 | 链接 | 简介 |
| :--- | :--- | :--- | :--- | :--- |
| ReAct: Synergizing Reasoning and Acting in Language Models | Shunyu Yao, et al. | 2022 | [Link](https://arxiv.org/abs/2210.03629) | 提出了 ReAct 框架，使 LLM 能够结合推理和行动。 |
| Toolformer: Language Models That Teach Themselves to Use Tools | Timo Schick, et al. | 2023 | [Link](https://arxiv.org/abs/2302.04761) | 训练 LLM 自主学习使用外部工具（API）。 |
| Generative Agents: Interactive Simulacra of Human Behavior | Joon Sung Park, et al. | 2023 | [Link](https://arxiv.org/abs/2304.03442) | 创建了能够模拟人类行为的生成式智能体。 |

---

## 💡 应用

| 论文标题 | 作者 | 发表年份 | 链接 | 简介 |
| :--- | :--- | :--- | :--- | :--- |
| CodeX: Evaluating Large Language Models on Code | Mark Chen, et al. | 2021 | [Link](https://arxiv.org/abs/2107.03374) | 介绍了 CodeX，一个在代码生成方面表现出色的 LLM。 |
| Chain-of-Thought Prompting Elicits Reasoning in Large Language Models | Jason Wei, et al. | 2022 | [Link](https://arxiv.org/abs/2201.11903) | 提出了思维链（CoT）提示，以激发 LLM 的推理能力。 |
| Large Language Models as Optimizers | Chengrun Yang, et al. | 2023 | [Link](https://arxiv.org/abs/2309.03409) | 探索了使用 LLM 作为优化器的潜力。 |

---

## 📊 评估

| 论文标题 | 作者 | 发表年份 | 链接 | 简介 |
| :--- | :--- | :--- | :--- | :--- |
| GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding | Alex Wang, et al. | 2018 | [Link](https://arxiv.org/abs/1804.07461) | 提出了 GLUE，一个广泛使用的 NLU 评估基准。 |
| SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems | Alex Wang, et al. | 2019 | [Link](https://arxiv.org/abs/1905.00537) | GLUE 的升级版，包含更具挑战性的任务。 |
| MMLU: Measuring Massive Multitask Language Understanding | Dan Hendrycks, et al. | 2020 | [Link](https://arxiv.org/abs/2009.03300) | 提出了 MMLU，一个用于评估 LLM 多任务知识的基准。 |
