---
title: 数据探索
draft: false
tags:
  - 数据科学
---
# 数据探索步骤
1. 变量识别：输入什么、输出什么、变量类型
2. 变量分析：单边量、双变量
3. 缺失值处理
4. 异常值处理
5. 变量转换
6. 新变量生成

# 为什么要进行数据探索
在机器学习中，进行数据探索的目的是为了更好地理解数据的特征、结构和潜在问题，以便为后续的建模和分析奠定基础，提供方向 。具体来说，数据探索的主要目的包括以下几点：

1. **了解数据的基本特征**：数据探索有助于理解数据的基本统计特性，如均值、中位数、方差、分布形状等。这些信息有助于识别数据的总体趋势和潜在的模式。
    
2. **发现数据中的异常值和缺失值**：数据可能包含异常值或缺失值，这些问题可能会影响模型的性能。在数据探索过程中，识别并处理这些问题是至关重要的。
    
3. **识别变量之间的关系**：通过数据探索，可以识别不同变量之间的相关性或其他关系，如线性关系或非线性关系。这些信息有助于选择特征和构建模型。
    
4. **检测数据分布**：不同变量的数据分布情况（如正态分布、偏态分布等）会影响模型的选择和性能。通过探索，可以决定是否需要进行数据转换或标准化。
    
5. **评估数据质量**：数据探索有助于评估数据的完整性、准确性和一致性，从而决定是否需要进行数据清洗或预处理。
    
6. **为模型选择提供依据**：通过对数据的探索，可以为选择合适的机器学习算法和模型提供依据。例如，了解数据的特征分布可以帮助选择更适合的模型。

# 数据探索如何为模型选择提供依据
数据探索（Exploratory Data Analysis, EDA）在模型选择过程中起着至关重要的作用，通过全面了解数据的结构和特性，研究人员和数据科学家可以更有针对性地选择和调整机器学习模型。以下是数据探索如何为模型选择提供依据的详细说明：

## 1. **理解数据类型和特征分布**
   - **数据类型**：不同的模型对数据类型的处理能力不同。比如，线性回归要求特征是数值型的，而决策树和随机森林可以处理分类特征和数值特征。因此，理解特征的类型（数值型、分类型、文本型等）有助于选择适当的模型。
   - **分布形态**：数据探索有助于了解各个特征的分布情况（如正态分布、偏态分布、离散分布等）。一些模型如线性回归、逻辑回归在假设变量服从正态分布时效果更好，而对分布没有严格要求的模型（如决策树）则不受此影响。如果数据不符合假设，可以考虑数据转换或者选择更适合的模型。

## 2. **变量之间的相关性分析**
   - **线性相关性**：通过计算相关系数（如皮尔逊相关系数），可以评估特征与目标变量之间的线性关系。若存在强线性相关性，线性模型（如线性回归、岭回归）可能表现良好。反之，如果相关性较弱或存在复杂的非线性关系，可能需要选择更复杂的模型（如神经网络、支持向量机）。
   - **多重共线性**：如果特征之间存在高度相关性（多重共线性），可能会影响线性模型的稳定性和预测能力。在数据探索中识别这种情况，可以选择适合处理共线性的模型（如岭回归、LASSO）或通过特征选择来消除冗余特征。

## 3. **数据的线性可分性**
   - **线性可分性**：在探索数据时，如果发现特征空间中不同类别的样本可以通过直线或超平面很好地分开，则线性模型（如逻辑回归、线性支持向量机）可能是不错的选择。反之，若数据呈现复杂的、非线性的分布，则需要考虑非线性模型（如核方法的支持向量机、决策树、随机森林等）。

## 4. **数据分布的平衡性**
   - **类别不平衡**：如果目标变量是分类变量且类别不平衡，某些模型（如朴素贝叶斯、KNN）可能对少数类表现不佳。在数据探索中发现这种情况后，可以考虑使用对类别不平衡更具鲁棒性的模型（如随机森林、梯度提升树）或者通过调整决策阈值、使用平衡样本策略（如SMOTE）等方法来优化模型表现。

## 5. **数据规模和特征维度**
   - **数据规模**：大规模数据集通常更适合使用能够扩展至大数据的模型（如随机森林、梯度提升树、深度学习模型）。而对于小规模数据集，简单模型（如线性回归、逻辑回归、KNN）可能表现更好且易于解释。
   - **特征维度**：当数据的特征维度非常高时（如文本数据的词向量表示），一些模型（如线性模型、支持向量机）可能更适合。而对于低维度数据，决策树、KNN等模型可能更具解释性。

## 6. **异常值和噪声处理**
   - **异常值**：在数据探索中识别异常值可以帮助决定是否选择对异常值敏感或鲁棒的模型。比如，线性模型容易受到异常值的影响，而决策树、随机森林等模型对异常值相对不敏感。
   - **噪声**：数据探索可以揭示数据中的噪声水平。对于噪声较多的数据，选择对噪声不敏感的模型（如基于决策树的集成模型、神经网络）可能更为合适。

## 7. **数据的时间序列特性**
   - **时间序列特性**：如果数据具有时间序列特性（如趋势、季节性），探索数据可以帮助选择合适的时间序列模型（如ARIMA、LSTM），而不是传统的回归或分类模型。

通过这些数据探索的步骤，可以为模型选择提供重要的指引，帮助研究人员选择最适合数据特性和业务需求的模型，从而提高预测准确性和模型的鲁棒性。


# 数据探索的详细方法
## 1. 变量识别
拿到数据集，首先要确定自己的目的是什么，然后了解数据集哪些是输入变量，输出变量；
确定变量的数据类型，哪些是字符串、时间、浮点、整数等；
确定哪些变量是连续型变量，哪些是类别型变量

## 2. 变量分析
### 2.1 单变量分析
- 对于连续型变量，主要看其中心分布趋势
- 对于类别型变量，主要是看其频次（次数）和频率（占比），可用于柱形图来表示可视化分布情况

### 2.2 双变量分析
- 连续型和连续型
	用二维点阵图，和计算相关性来分析连续型与连续型双变量。
	用皮尔逊相关系数看，特征和目标值之间存在强的相关性，那适合用线性模型；如果特征和特征之间存在强相关性，也就是说存在多重共线性，岭回归和Lasso适合解决这类问题，可以进行特征选择。
- 连续型和类别型
	可以绘制小提琴图，横坐标维类别变量，纵坐标为连续型变量，查看每种类别的数据分布情况
- 类别型和类别型
	可以使用堆叠柱状图和卡方检验、双向表进行分析。
	卡方检验，主要用于两个或两个以上样本率及两个二值型离散变量的关联性分析，即比较理论频次与实际频次的吻合程度或拟合优度

>[!info] Q-Q图和KDE图、线性关系图
> Q-Q图，是指数据的分位数和正态分布的分位数对比参照的图，是为了看变量是否符合正态分布，如果发现不一致的变量可进行数据转换
> 
> KDE图，即核密度估计， 可以理解为是对直方图的加窗平缓，通过KDE分布图，可以查看并对比训练集和测试集中特征变量的分布情况，发现两个数据集中分布不一致的特征变量，可进行删除
> 
> 线性关系图，查看变量与目标值之间关系，


 
## 3. 缺失值处理
缺失值主要分为一下四类：
- 完全随机丢失
- 随机丢失
- 不可预测因子导致的确实
- 取决于自身的缺失

缺失值处理方法：
- 删除
	- 成列删除
		删除任何变量丢失的观察结果
	- 成行删除
		删除对应缺失值
- 平均值、众数、中值填充
- 预测模型填充

## 4. 异常值处理
异常值可能是由数据输入，测量误差、实验误差、数据采集等产生的误差。
异常值对模型和预测分析的影响主要有增加错误方差，降低模型的拟合能力；异常值的非随机分布会降低正态性；与真实值可能存在偏差；影响召回、方差分析等统计模型的基本假设。

### 4.1 异常值检测
一般采用可视化方法进行异常值检测，常用工具包括箱线图、直方图、散点图等，一般使用箱线图较多。
>[!info] 说明
>由于异常值只是对有影响的特殊数据点进行检测，因此它的选择也取决于对于业务的理解

### 4.2 异常值的处理方法
对异常值一般采用删除、转换、填充、区别对待等方法进行处理
- 删除：能够甄别出明显是人为输入错误，或者超出设定范围值，比如冰箱温度明显是不能成百上千度的
- 转换：通过取对数，可以消除异常值的影响
- 填充：像处理缺失值那样，对异常值用平均值、中值等进行填充
- 区别对待：如果存在大量的异常值，则应该在统计模型中区别对待，其中一个方法是将数据分为两个不同的组，异常值归为一组，正常值归为一组，两组分别建模

## 5. 变量转换
### 5.1 转换目的
在分析过程中，发现变量分布不均匀，会极大影响估计，为此，需要对变量的取值区间等进行转换，使其分布落在合理区间内

### 5.2 变量转换方法

| 变量转换方法       | 说明                                           |
| ------------ | -------------------------------------------- |
| 缩放比例或标准化     | 数据具有不同的缩放比例，其不会更改变量的分布                       |
| 非线性关系转换成线性关系 | 将非线性变量的关系转换为线性关系更容易理解，其中对数变换是常用的一种           |
| 使倾斜分不对称      | 对于右倾斜的分布，对变量取平方根或立方根或对数；对于左倾斜分布，对变量取平方或立方或指数 |
| 变量分组         | 根据不同的目标把变量按不同类别分组                            |
Box-Cox变换，对变量进行转换，这一变换可以线性回归模型在满足线性、正态性、独立性及方差其次性，又不丢失信息

Box-Cox变换，先进性归一化预处理

## 6. 新变量生成

### 6.1 变量生成目的
变量生成是基于现有变量生成新的变量，生成的新变量可能与目标变量有更好的相关性，有助于数据分析

### 6.2 变量生成方法
- 创建派生变量
- 创建哑变量

