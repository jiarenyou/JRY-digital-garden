---
title: 模型验证
draft: false
tags:
  - 机器学习
---

# 模型评估的概念和方法
## 欠拟合和过拟合
- 欠拟合：高偏差，是指所训练的模型不能完整地表达数据关系。解决方法是可以通过增加额外特征，增加多项式特征，减少λ的值来优化模型
- 过拟合：高方差，是指算法模型过高的表达了数据关系，应用到未接触过的数据，显示出了较差的水平，解决方法是收集更多的数据、使用更少的特征，增加λ的值等方法来优化模型

## 模型的泛化与正则化
模型的泛化能力就是要在过拟合和欠拟合直接之间找到最适合的模型，

正则化是给需要训练的目标函数，大多是损失函数，加上一些规则（限制），目的是为了防止过拟合。
常用的正则化方法有L1和L2范数，详细可以看[[L1、L2、拉格朗日乘数法、KKT条件]]。
对损失函数添加正则项，可以减少模型学习到的θ的大小，这样可以是模型的泛化能力更强。
用L1范数正则化的线性模型叫岭回归
用L2范数正则化的线性模型叫Lasso回归

正则化目的是为了防止过拟合，原理是在损失函数上加上某些规则，缩小解空间，从而减少求过拟合的可解性。

## 回归模型的评估指标和调用方法
- 平均值绝对误差（MAE）
- 均方误差（MSE）
- 均方根误差（RMSE）
- R平方值（R-Squared）

### 平均值绝对误差（MAE）
平均值绝对误差（MAE）是预测值与实际值之差的平均值
$$ MAE=\frac{1}{n}\sum_{i=1}^{n}{\mid{f_i - y_i}}\mid = \frac{1}{n}\sum_{i=1}^{n}{\mid{e_i}\mid} $$


### 均方误差（MSE）

均方误差是指参数估计值与参数真实值之差平方的期望值，MSE是平衡平均误差的一种较方便的方法，可以用来评价数据的变化程度。MSE的值越小，说明预测模型描述实验数据具有约好的精确度
$$ MSE=\frac{1}{n}\sum_{i=1}^{n}{(y_i - f_i)^2}  $$

### 均方根误差
RMSE是MSE的平方根。
$$ RMSE=\sqrt{\frac{1}{n}\sum_{i=1}^{n}{(y_i - f_i)^2}}  $$

### R平方
R平方值反应回归模型在多大程度上解释了因变量的变化，或者说模型对观测值得拟合程度如何
$$ R^2(y, \hat{y}) = 1- \frac{
						\sum_{i=0}{n_{sample}}^{-1}{(y_i-\hat{y_i})^2}}
						{\sum_{i=0}{n_{sample}}^{-1}{(y_i-\bar{y_i})^2}}$$



## 交叉验证
交叉验证是验证分类器性能的一种统计分析方法，基本思想实在某种意义下将原始数据进行分组，一组作为训练集，另一部分作为验证集。首先用训练集对分类器进行训练，再用验证集来测试训练得到的模型，以此来作为评价分类器的性能指标
### 简单交叉验证

### K折交叉验证

### 留一法交叉验证

### 留P法交叉验证



## 模型调参

### 调参目标
调参是多模型的参数进行调整，找到最优的参数，即使得模型的偏差和方差的大和谐。
参数可分为两类：过程影响类参数，子模型影响类参数
- 过程类影响参数，在子模型不变的前提下，调整“子模型数”、“学习率”等参数，改变训练过程，从而提高整体模型性能。
- 子模型影响类参数，就是调整最大树深度、分裂条件等参数，改变子模型的性能，从而提高整体模型性能

bagging的训练过程旨在降低方差，boosting的训练过程旨在降低偏差
过程影响类参数能够引起整体模型性能的大幅度变化


### 网格搜索
网格搜索是一种穷举搜索的调参手段

### 学习曲线
学习曲线在训练集大小不同时，通过绘制模型训练集和交叉验证集的准确率来观察模型在新数据上的表现，进而判断模型的方差或偏差是否过高，以及增大训练集是否可以减小过拟合

### 验证曲线
